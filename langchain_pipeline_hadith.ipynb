{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, dotenv_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API KEYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n",
      "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\n",
      "sk-proj-mO7ul2Am4ejmD4YNZMW7T3BlbkFJdG1j5bof6oHms0qYMlOZ\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "LS_TOKEN = os.getenv(\"LS_TOKEN\")\n",
    "OpenAI_TOKEN = os.getenv(\"OpenAI_API_KEY\")\n",
    "print(LS_TOKEN)\n",
    "print(OpenAI_TOKEN)\n",
    "os.environ[\"LANG_SMITH_API_KEY\"] = LS_TOKEN\n",
    "os.environ[\"OPEN_AI_API_KEY\"] = OpenAI_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = LS_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = OpenAI_TOKEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOCUMENTS LOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from langchain.schema import Document\n",
    "\n",
    "with open('D:/Data Science Projects/Scalence Internship ML/Bukhari-Muslim-RAG/first_50.csv') as file:\n",
    "    lines = csv.reader(file)\n",
    "    \n",
    "    documents_b_m = []\n",
    "    # embeddings_b_m = []\n",
    "    metadatas_b_m = []\n",
    "    ids_b_m = []\n",
    "    id = 1\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        if i==0:\n",
    "            continue\n",
    "        \n",
    "        #Code to store ahadith in variables with embeddings, metadatas and ids\n",
    "        documents_b_m.append(line[2])\n",
    "        # embeddings_b_m.append(model.encode(line[2]).tolist())\n",
    "        metadatas_b_m.append({\"hadith_id\": line[1],\"source\": line[0]})\n",
    "        ids_b_m.append(str(id))\n",
    "        id+=1\n",
    "    \n",
    "# Create a list of document objects from your plain text documents.   \n",
    "documents_b_m_object = [Document(page_content=text, metadata={}) for text, metadata in zip(documents_b_m, metadatas_b_m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents_b_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents_b_m_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already splitted. (No need for Splitter) ^^^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKE A VECTOR STORE AND STORE AHADITH WITH EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadatas_b_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(metadatas_b_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = 'bukhari_muslim_langchain_collection'\n",
    "persist_directory = \"D:/Data Science Projects/Scalence Internship ML/Bukhari-Muslim-RAG/chroma\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_texts(\n",
    "    texts = documents_b_m,\n",
    "    embedding = OpenAIEmbeddings(),\n",
    "    metadatas = metadatas_b_m,\n",
    "    ids = ids_b_m,\n",
    "    collection_name = collection_name,\n",
    "    persist_directory = persist_directory\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKE PROMPT FOR CHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### RETRIEVAL and GENERATION ####\n",
    "from langchain import hub\n",
    "\n",
    "# Prompt\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKE LLM FOR CHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing\n",
    "def format_docs(documents_b_m):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in documents_b_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKE A RAG CHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAKE A QUERY USING THE CHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The Prophet distributed Zakat among people, leaving out a man Sa'd thought highly of. When asked why, the Prophet explained that he gives to others out of fear they may face punishment. Sa'd persisted in his questioning due to his belief in the man's faith.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question\n",
    "rag_chain.invoke('''Narrated Sa'd:                          Allah's Apostle distributed (Zakat) amongst (a group of) people while      I was sitting there but Allah's Apostle left a man whom I thought the      best of the lot. I asked, \"O Allah's Apostle! Why have you left that      person? By Allah I regard him as a faithful believer.\" The Prophet      commented: \"Or merely a Muslim.\" I remained quiet for a while, but      could not help repeating my question because of what I knew about him.     And then asked Allah's Apostle, \"Why have you left so and so? By      Allah! He is a faithful believer.\" The Prophet again said, \"Or merely      a Muslim.\" And I could not help repeating my question because of what      I knew about him. Then the Prophet said, \"O Sa'd! I give to a person      while another is dearer to me, for fear that he might be thrown on his     face in the Fire by Allah.\"''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
